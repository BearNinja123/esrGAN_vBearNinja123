{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8L-29qhC2TXi"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.losses import *\n",
    "from tensorflow.keras.applications import VGG19\n",
    "import tensorflow.keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import joblib, os, cv2, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9QFEZ6Uc2oSh"
   },
   "outputs": [],
   "source": [
    "# take in training data\n",
    "\n",
    "os.chdir('train')\n",
    "rawX = joblib.load('lrImgs.sav')\n",
    "rawX2 = joblib.load('hrImgs.sav')\n",
    "os.chdir('..')\n",
    "\n",
    "m = rawX.shape[0]\n",
    "batchSize = 16\n",
    "X = tf.data.Dataset.from_tensor_slices(rawX).batch(batchSize)\n",
    "X2 = tf.data.Dataset.from_tensor_slices(rawX2).batch(batchSize)\n",
    "listX = list(X.as_numpy_iterator())\n",
    "listY = list(y.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CCxLQyxb2u-J"
   },
   "outputs": [],
   "source": [
    "def buildGBlock(inp):\n",
    "  cv1 = Conv2D(64, 3, padding='same')(inp)\n",
    "  bn1 = BatchNormalization()(cv1)\n",
    "  r1 = LeakyReLU()(bn1)\n",
    "  cv2 = Conv2D(64, 3, padding='same')(r1)\n",
    "  bn2 = BatchNormalization()(cv2)\n",
    "  pr2 = Add()([inp, bn2])\n",
    "  return pr2\n",
    "\n",
    "def buildGBlockNoBN(inp):\n",
    "  cv1 = Conv2D(64, 3, padding='same')(inp)\n",
    "  r1 = LeakyReLU()(cv1)\n",
    "  cv2 = Conv2D(64, 3, padding='same')(r1)\n",
    "  add = Add()([inp, cv2])\n",
    "  return add\n",
    "\n",
    "def buildDBlock(inp):\n",
    "  cv1 = Conv2D(32, 3, strides=2, padding='same')(inp)\n",
    "  bn1 = BatchNormalization()(cv1)\n",
    "  lr1 = LeakyReLU()(bn1)\n",
    "  d1 = Dropout(0.2)(lr1)\n",
    "  return d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5uMucXYEQrBx"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Building model architectures - a far cry from that in the paper, but it worked for me.\n",
    "\n",
    "Changes:\n",
    "No PReLU - too many parameters and not much improvement\n",
    "No PixelShuffle - there isn't a Keras layer for that and PixelShuffle didn't\n",
    "help too much anyway\n",
    "Conv2DTranspose and UpSampling2D layers - Conv2D gave ugly dots on the SR image,\n",
    "UsSampling2D didn't give much detail, both worked when together\n",
    "No BN after upsampling - Make sure that the dots from the deconv. layers \n",
    "wouldn't be as noticeable in the final SR image\n",
    "'''\n",
    "\n",
    "def genGen():\n",
    "  inp = Input((64, 64, 3))\n",
    "  layer = Conv2D(64, 5, padding='same')(inp)\n",
    "  layer = LeakyReLU()(layer)\n",
    "  us1 = UpSampling2D()(layer)\n",
    "  us2 = UpSampling2D()(us1)\n",
    "\n",
    "  for i in range(2):\n",
    "    layer = buildGBlock(layer)\n",
    "\n",
    "  layer = Conv2DTranspose(64, 3, strides=2, padding='same')(layer)\n",
    "  layer = LeakyReLU()(layer)\n",
    "  layer = Add()([layer, us1])\n",
    "  layer = Conv2DTranspose(64, 3, strides=2, padding='same')(layer)\n",
    "  layer = LeakyReLU()(layer)\n",
    "  layer = Add()([layer, us2])\n",
    "  \n",
    "  for i in range(2):\n",
    "    layer = buildGBlockNoBN(layer)\n",
    "    layer = Add()([layer, us2])\n",
    "\n",
    "  output = Conv2D(3, 5, padding='same', activation='sigmoid')(layer)\n",
    "\n",
    "  generator = Model(inp, output, name='generator')\n",
    "  return generator\n",
    "\n",
    "def genDisc():\n",
    "  inp = Input((128, 128, 3))\n",
    "  layer = Conv2D(32, 3, padding='same')(inp)\n",
    "  layer = LeakyReLU()(layer)\n",
    "\n",
    "  for i in range(5):\n",
    "    layer = buildDBlock(layer)\n",
    "\n",
    "  flat = Flatten()(layer)\n",
    "  output = Dense(1, activation='sigmoid')(flat)\n",
    "  discriminator = Model(inp, output, name='discriminator')\n",
    "\n",
    "  return discriminator\n",
    "\n",
    "def build_vgg():\n",
    "  vgg = VGG19(input_shape=(128, 128, 3), include_top=False, weights=\"imagenet\")\n",
    "  vgg.outputs = [vgg.layers[6].output]\n",
    "  inputLayer = vgg.layers[0].output\n",
    "\n",
    "  return Model(inputLayer, vgg.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "5mVlK31V4oHO",
    "outputId": "3c99271d-7b4b-428c-ffed-d5e4660e0aa3"
   },
   "outputs": [],
   "source": [
    "bce = BinaryCrossentropy()\n",
    "\n",
    "def discLoss(ytrue, yfake):\n",
    "  global bce\n",
    "  trueLoss = bce(tf.ones_like(ytrue), ytrue)\n",
    "  fakeLoss = bce(tf.zeros_like(yfake), yfake)\n",
    "  return K.mean(trueLoss + fakeLoss)\n",
    "\n",
    "def genLoss(yfake, y, fakeImgs):\n",
    "  global bce\n",
    "  alpha = 0.2 # not found in the paper, but allowed me to change how dependent the loss was on advesarial or perceptual loss\n",
    "  mse = MeanSquaredError()\n",
    "  recLoss = (1 - alpha) * mse(y, fakeImgs)\n",
    "  adLoss = alpha * K.mean(bce(tf.ones_like(yfake), yfake))\n",
    "  return recLoss + adLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SGQ7U5S84Se4"
   },
   "outputs": [],
   "source": [
    "def step(batch, y):\n",
    "  global genModel, discModel, vgg, genOpt, discOpt\n",
    "  with tf.GradientTape() as gtape, tf.GradientTape() as dtape:\n",
    "    fakes = genModel(batch, training=True)\n",
    "    truePreds = discModel(y, training=True)\n",
    "    fakePreds = discModel(fakes, training=True)\n",
    "    fakeMean, trueMean = K.mean(fakePreds).numpy(), K.mean(truePreds).numpy()\n",
    "    print('Fake Preds: {} | True Preds: {}'.format(fakeMean, trueMean))\n",
    "    trueVGG = vgg(y, training=False)\n",
    "    fakeVGG = vgg(fakes, training=False)\n",
    "\n",
    "    dloss = discLoss(truePreds, fakePreds)\n",
    "    gloss = genLoss(fakePreds, trueVGG, fakeVGG)\n",
    "\n",
    "    # cripple the generator/discriminator if they got too good, made adversarial training more stable\n",
    "    if fakeMean < 0.7:\n",
    "      gradGen = gtape.gradient(gloss, genModel.trainable_variables)\n",
    "      genOpt.apply_gradients(zip(gradGen, genModel.trainable_variables))\n",
    "    if trueMean < 0.7 or fakeMean > 0.3:\n",
    "      gradDisc = dtape.gradient(dloss, discModel.trainable_variables)\n",
    "      discOpt.apply_gradients(zip(gradDisc, discModel.trainable_variables))\n",
    "    \n",
    "  return dloss, gloss\n",
    " \n",
    "def train(X, y, epochs, steps=1000):\n",
    "  global m, batchSize, listX, listY\n",
    "  for i in range(epochs):\n",
    "    dcost = 0\n",
    "    gcost = 0\n",
    "    gloss = 0\n",
    "    for batch in range(steps):\n",
    "      batchInd = np.random.randint(low=0, high=m//batchSize)\n",
    "      batchX = listX[batchInd]\n",
    "      batchY = listY[batchInd]\n",
    "      dloss, gloss = step(batchX, batchY, gloss)\n",
    "      print('Batch: {} | Discriminator Batch Loss: {} | Generator Batch Loss: {}'.format(batch, dloss, gloss))\n",
    "\n",
    "      dcost += dloss\n",
    "      gcost += gloss\n",
    "\n",
    "    print('\\n-----Epoch: {} | Discriminator Cost: {} | Generator Cost: {}-----\\n'.format(i, dcost, gcost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SFSY5-aL4tWo",
    "outputId": "7d073b56-5bfb-4d62-90ca-aeb7066b7bb8",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vgg = build_vgg()\n",
    "vgg.trainable = False\n",
    "\n",
    "genModel = genGen()\n",
    "discModel = genDisc()\n",
    "\n",
    "# load in trained model\n",
    "'''\n",
    "if tf.__version__ == '2.2.0':\n",
    "  genModel = tf.keras.models.load_model('models/tf_220/srGAN/gen')\n",
    "  discModel = tf.keras.models.load_model('models/tf_220/srGAN/disc')\n",
    "else:\n",
    "  genModel = tf.keras.models.load_model('models/tf_230/srGAN/gen')\n",
    "  discModel = tf.keras.models.load_model('models/tf_230/srGAN/disc')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UpSHGU_zkWZw"
   },
   "outputs": [],
   "source": [
    "genOpt = Adam(learning_rate=1e-4) # Adam's my guy\n",
    "discOpt = Adam(learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6qybK3Ju5NUk"
   },
   "outputs": [],
   "source": [
    "# train the model and show its results\n",
    "\n",
    "while True:\n",
    "  rows, cols = 3, 5\n",
    "  fig = plt.figure(figsize=(30, 15))\n",
    "  axes = fig.subplots(rows, cols)\n",
    "  for i in range(cols):\n",
    "    if i % 2 == 0:\n",
    "      predInput = np.array([rawX[i]])\n",
    "      pred = genModel.predict(predInput)[0]\n",
    "    \n",
    "      axes[0][i].imshow(rawX[i])\n",
    "      axes[1][i].imshow(pred)\n",
    "      axes[2][i].imshow(rawX2[i])\n",
    "    else:\n",
    "      randI = np.random.randint(low=0, high=m)\n",
    "      predInput = np.array([rawX[randI]])\n",
    "      pred = genModel.predict(predInput)[0]\n",
    "\n",
    "      axes[0][i].imshow(rawX[randI])\n",
    "      axes[1][i].imshow(pred)\n",
    "      axes[2][i].imshow(rawX2[randI])\n",
    "\n",
    "  plt.show()\n",
    "  train(X, X2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fQ8Q5IqA8Pol"
   },
   "outputs": [],
   "source": [
    "now = time.time()\n",
    "if tf.__version__ == '2.2.0':\n",
    "  genModel.save('models/tf_220/srGAN_{}_{}/gen'.format(mode, now))\n",
    "  discModel.save('models/tf_220/srGAN_{}_{}/disc'.format(mode, now))\n",
    "else:\n",
    "  genModel.save('models/tf_230/srGAN_{}_{}/gen'.format(mode, now))\n",
    "  discModel.save('models/tf_230/srGAN_{}_{}/disc'.format(mode, now))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "srGAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
